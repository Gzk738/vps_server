<!DOCTYPE html>
<html lang="zh-CN">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.91.2" /><meta name="theme-color" content="#16171d" />
    <meta name="color-scheme" content="light dark">

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>IDS-Extract:Downsizing Deep Learning Model For Question and Answering | 铅笔与橡皮</title>

    <link rel="stylesheet" href="/css/meme.min.7b3fed119d405c05a5da57e22d7f0274a35ee05ae9fc047282343900f10e4afa.css"/>

    
    
        <script src="/js/meme.min.8cbe976441b5181abfd3093c9beee209b19cdbb1fa77c48d225a83ba81fa3fb1.js"></script>

    

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />

        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" media="print" onload="this.media='all'" />
        <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" /></noscript>

    <meta name="author" content="铅笔与橡皮" /><meta name="description" content="Published in: 2023 International Conference on Electronics, Information, and Communication (ICEIC)
Abstract: In recent years, Question-answering systems are extensively used in human-computer systems, and the accuracy rate on a large scale is increasing. However, in actual deployment, a large number of parameters are often accompanied by a large amount of memory and long-term processing requirements." />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2a6df4" />
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="铅笔与橡皮" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="铅笔与橡皮" />
    <meta name="msapplication-starturl" content="../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../icons/mstile-150x150.png" />
    <link rel="manifest" href="/manifest.json" />

    
    

    
    <link rel="canonical" href="https://guozikun.xyz/tech/ids/" />
    

<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "WebPage",
        "datePublished": "2022-12-23T22:11:35+09:00",
        "dateModified": "2023-04-23T22:17:41+09:00",
        "url": "https://guozikun.xyz/tech/ids/",
        "name": "IDS-Extract:Downsizing Deep Learning Model For Question and Answering",
        "description": "Published in: 2023 International Conference on Electronics, Information, and Communication (ICEIC)\nAbstract: In recent years, Question-answering systems are extensively used in human-computer systems, and the accuracy rate on a large scale is increasing. However, in actual deployment, a large number of parameters are often accompanied by a large amount of memory and long-term processing requirements.",
        "image": "https://guozikun.xyz/icons/apple-touch-icon.png",
        "license": "copyright hugo",
        "publisher": {
            "@type": "Organization",
            "name": "铅笔与橡皮",
            "logo": {
                "@type": "ImageObject",
                "url": "https://guozikun.xyz/icons/apple-touch-icon.png"
            },
            "url": "https://guozikun.xyz/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "https://guozikun.xyz/"
        }
    }
</script>

    

<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@gzk" />
<meta name="twitter:creator" content="@铅笔与橡皮" />

    



<meta property="og:title" content="IDS-Extract:Downsizing Deep Learning Model For Question and Answering" />
<meta property="og:description" content="Published in: 2023 International Conference on Electronics, Information, and Communication (ICEIC)
Abstract: In recent years, Question-answering systems are extensively used in human-computer systems, and the accuracy rate on a large scale is increasing. However, in actual deployment, a large number of parameters are often accompanied by a large amount of memory and long-term processing requirements." />
<meta property="og:url" content="https://guozikun.xyz/tech/ids/" />
<meta property="og:site_name" content="铅笔与橡皮" />
<meta property="og:locale" content="zh" /><meta property="og:image" content="https://guozikun.xyz/icons/apple-touch-icon.png" />
    <meta property="og:type" content="website" />

        <link rel="preconnect" href="https://www.google-analytics.com" crossorigin />

        


    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-DHN9LCYBT6"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-DHN9LCYBT6');
    </script>



        
            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
    (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "",
        enable_page_level_ads: true
    });
</script>


    
    

    
</head>

    <body>
        <div class="container">
            
    <header class="header">
        
            <div class="header-wrapper">
                <div class="header-inner single">
                    
    <div class="site-brand">
        
            <a href="/" class="brand">铅笔与橡皮</a>
        
    </div>

                    <nav class="nav">
    <ul class="menu" id="menu">
        
            
        
        
        
        
            
                <li class="menu-item"><a href="/tech/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon th"><path d="M149.333 56v80c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V56c0-13.255 10.745-24 24-24h101.333c13.255 0 24 10.745 24 24zm181.334 240v-80c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256 0 24.001-10.745 24.001-24zm32-240v80c0 13.255 10.745 24 24 24H488c13.255 0 24-10.745 24-24V56c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24zm-32 80V56c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256 0 24.001-10.745 24.001-24zm-205.334 56H24c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24zM0 376v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H24c-13.255 0-24 10.745-24 24zm386.667-56H488c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zm0 160H488c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zM181.333 376v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24z"/></svg><span class="menu-item-name">Tech</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/life/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" class="icon tags"><path d="M497.941 225.941L286.059 14.059A48 48 0 0 0 252.118 0H48C21.49 0 0 21.49 0 48v204.118a48 48 0 0 0 14.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882 0l204.118-204.118c18.745-18.745 18.745-49.137 0-67.882zM112 160c-26.51 0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882 0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397 0h48.721a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882z"/></svg><span class="menu-item-name">Life</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/about/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon user-circle"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg><span class="menu-item-name">About</span></a>
                </li>
            
        
            
                
                    
                    
                        <li class="menu-item">
                            <a id="theme-switcher" href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-light"><path d="M193.2 104.5l48.8-97.5a18 18 0 0128 0l48.8 97.5 103.4 -34.5a18 18 0 0119.8 19.8l-34.5 103.4l97.5 48.8a18 18 0 010 28l-97.5 48.8 34.5 103.4a18 18 0 01-19.8 19.8l-103.4-34.5-48.8 97.5a18 18 0 01-28 0l-48.8-97.5l-103.4 34.5a18 18 0 01-19.8-19.8l34.5-103.4-97.5-48.8a18 18 0 010-28l97.5-48.8-34.5-103.4a18 18 0 0119.8-19.8zM256 128a128 128 0 10.01 0M256 160a96 96 0 10.01 0"/></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-dark"><path d="M27 412a256 256 0 10154-407a11.5 11.5 0 00-5 20a201.5 201.5 0 01-134 374a11.5 11.5 0 00-15 13"/></svg></a>
                        </li>
                    
                
            
        
            
                
            
        
    </ul>
</nav>

                    
                </div>
            </div>
            
    <input type="checkbox" id="nav-toggle" aria-hidden="true" />
    <label for="nav-toggle" class="nav-toggle"></label>
    <label for="nav-toggle" class="nav-curtain"></label>


        
    </header>




            
            
    <main class="main single" id="main">
    <div class="main-inner">

        

        <article class="content post h-entry" data-align="justify" data-type="tech" data-toc-num="true">

            <h1 class="post-title p-name">IDS-Extract:Downsizing Deep Learning Model For Question and Answering</h1>

            

            
                
            

            
                

<div class="post-meta">
    
    
    
    
        
        
        
            
        
    
    
        
        <span class="post-meta-item wordcount"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;2978</span>
    
    
        
        <span class="post-meta-item reading-time"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;14&nbsp;分钟</span>
    
    
        
            
            <span class="post-meta-item busuanzi-page-pv" id="busuanzi_container_page_pv"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" class="icon post-meta-icon"><path d="M288 144a110.94 110.94 0 0 0-31.24 5 55.4 55.4 0 0 1 7.24 27 56 56 0 0 1-56 56 55.4 55.4 0 0 1-27-7.24A111.71 111.71 0 1 0 288 144zm284.52 97.4C518.29 135.59 410.93 64 288 64S57.68 135.64 3.48 241.41a32.35 32.35 0 0 0 0 29.19C57.71 376.41 165.07 448 288 448s230.32-71.64 284.52-177.41a32.35 32.35 0 0 0 0-29.19zM288 400c-98.65 0-189.09-55-237.93-144C98.91 167 189.34 112 288 112s189.09 55 237.93 144C477.1 345 386.66 400 288 400z"/></svg>&nbsp;<span id="busuanzi_value_page_pv"></span></span>
        
    
    
</div>

            

            <div class="post-body e-content">
                <p style="text-indent:0"><span class="drop-cap">P</span>ublished in: 2023 International Conference on Electronics, Information, and Communication (ICEIC)</p>
<h2 id="abstract"><a href="#abstract" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Abstract:</h2>
<p>In recent years, Question-answering systems are extensively used in human-computer systems, and the accuracy rate on a large scale is increasing. However, in actual deployment, a large number of parameters are often accompanied by a large amount of memory and long-term processing requirements. Therefore, compressing the data of the model, reducing training time, memory, becomes more and more urgent. we aim to resolve issues: IDS-Extract dynamically sized data to support models and devices with different memory. The proposed technique does efficient data extraction, segments that are not meaningful for model learning on the original dataset and output multiple datasets of adaptive size followed by target training based on model size. We leverage techniques in IG(Integration Gradient), DPR, and SBERT to improve localization performance for answer positions. We compare the model performance of SQuAD and the data set reduced by the IDS extraction technique, and the results prove that our technique can train the model more targeted and obtain higher performance evaluation. We prove that this method has successfully passed the sanity check, and can be directly applied to emotion recognition, two-classification, and multi-classification fields.</p>
<h2 id="section-iintroduction"><a href="#section-iintroduction" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>SECTION I.Introduction</h2>
<p>Pre-trained model such as based language models such as Transformer[1] BERT[2], T5[3] have achieved impressive performance on various downstream NLP tasks. These models are the current state of art research, using self-supervised methods to conduct and train in the corpus, and then fine-tune in specific tasks, which can ensure the semantic understanding ability of the model, and reduce the training cost of downstream tasks. Although they are effective, These models are difficult to target for various downstream tasks and resource-constrained scenarios and are therefore very expensive in terms of computational and memory costs, making them to train for this reason. Therefore, it becomes increasingly important to compress the resources required for pretrained models. There are many studies using different methods to compress pretrained models, such as pruning [4], weight decomposition [5], resistance [6] and knowledge distillation [7]. However, from a training perspective, if we use a lower memory device for pre-training or fine-tuning, the training time is often very long due to the low device performance. For example, if an embedded device is used instead of an online server, it is often faced with a low-memory training device. Another convenience is that when using the old method to train the model to adapt to the next task, the effect of a professional training server is often higher than that of a model trained by a computer or an embedded device. But compressing this operation for all models is laborious and cannot be passed from one task to another.In this paper, we investigate different information extraction settings: the extracted datasets need to cover different sizes to support devices with different types of memory; the extraction is in the fine-tuning phase, independent of training. In this work we propose IDS-Extraction, which utilizes dense passage retrieval (DPR), SBERT, and Integration Gradient to automatically extract context. We are concerned with fully designing with a space of search and separable extraction models. For example, in classification models, this approach can clearly tell us what is more important in deep networks, The advantage of this is that developers not only know the deep network's output, and can help them debug. Axiom - Sensitivity and implementation form the working method of the integral gradient, which is a derivative design based on the sensitivity axiom, which has the advantage of not requiring modification or optimization for a certain class of models and unifying deep model attribution Importance analysis under inference performance. After inputting sequence information into the model to get predictions, the standard method of gradient integration does not have an impact on the model work province and can quickly help developers or researchers to obtain the rule extraction features and progress of deep models, whether it is multi-image processing, text processing Or any form of data, such as tabular data, can demonstrate the attribution inference ability of deep network model， and enable users to better interact with the model. In order to make the model adaptive sizes to meet different embedded devices or mobile phones with different memory and different performance, we design a weighted extraction architecture that includes all candidate operations. In order to improve the pertinence in SQuAD[8], we directly train and specify different datasets to train the model. However, training directly in large networks is extremely expensive on pre-training tasks with large memory and long-running requirements. Improve the convergence efficiency and accuracy of the model, we use block-by-block training to divide the data into blocks in order to classify large, medium and small datasets.</p>
<h2 id="section-iirelated-work"><a href="#section-iirelated-work" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>SECTION II.Related Work</h2>
<p>Recently, compressing pretrained models has been extensively studied and several techniques have been proposed, such as knowledge distillation, pruning, weight decomposition, quantization, etc. Existing works aim to compress pretrained models into fixed-size models and strike a balance between small parameter sizes (usually no more than 66M) and good performance. However, these compression models cannot be deployed in devices with different memory and latency constraints. Recent works can provide adaptive models for each specific downstream task and demonstrate the effectiveness of task-oriented compression. For actual deployment, from each task. Other works are available in a pre-training stage that can generalize directly to downstream tasks and allow for efficient pruning at inference time. Different from existing work, IDS-Extraction aims at the compression of the fine-tuning stage independent of the compression of the model itself, eliminates the heavy compression of the model structure, and carefully designs the training architecture that can explore the potential and provide different models given different data require. This session can be compressed more.</p>
<p>A. DPR(Dense Paragraph Retrieval)
Dense Passage Retrieval [9] an unsupervised pre-training model for retrieval, different pre-retrieval training tasks, there are a high-efficiency general-propose technology has been proposed the Inverse Cloze Task [10], According to the experimental results of previous research, the application of dense paragraph retrieval can be applied in daily life such as Q&amp;A Bot [11], information retrieval [12], dialogue [13], and entity linking [14] can effectively improve the performance of the model and propose a new method that using a pre-train method with trains a masked sequence data model and a retriever.</p>
<p>However, the lack of lexical overlap between questions and answers in many question answering datasets makes standard IR methods that rely on strict lexical matching less applicable. Some IR systems have been modified to use BM25 [15] similarity to align query words with the most similar document words for various tasks including document matching, short text similarity, and answer selection. Also passages in low-dimensional semantic space have significantly outperformed traditional term-based techniques [16]. In this study, we practically achieve context extraction for retrieval and Integration Gradient [17] using dense representations, where the embeddings are learned from a small number of questions and passages via a simple two-encoder framework. The encoded information processed based on SBERT [18] is extracted from it. At the same time we use as a tool to elucidate important aspects of the learned model is extracted from it. At the same time we use as a tool to elucidate important aspects of the learned model, The purpose is to highlight the part of the input that positively contributes to the result. Although research has shown that the method has played a role, the definition and methodology of interpretability are still largely lacking. The lack of principled guidance confuses practitioners when deciding between a multitude of competing approaches.</p>
<p>B. SBERT(Sentence-BERT)
SBERT, a modification of the pretrained BERT network that use Siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be Compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa [19] to about 5 seconds with SBERT, while maintaining the accuracy from BERT.</p>
<p>C. IG(Integration Gradient)
while query-centric similarity relationships can enforce the position of the searched answer, the length of the sequence data is not something that all models can handle. When issuing a new query, once the length exceeds the maximum length that the model can handle: this often happens, especially in the OpenQA field, it is difficult to distinguish the performance bottleneck of the model itself or the data mismatch problem. The goal of explanation of the deep neural network is to Increase the model’s transparency to humans. The reasoning behind it can be explained in a way that humans can understand. In the effort to provide explanations, visualizing a certain amount of interest, such as the importance of input features or learning weights, becomes the most direct way to gain user trust. A novel Hindsight explanation method called Score-CAM based on class activation mapping. Increasing attention has been well-studied.</p>
<p>To address this issue, We use an encoder structure for paragraph similarity relations for reinforcement The basic idea is shown in Figure 2 shown, where we set an additional constraint s(p, q) : query the value between the similarity between q and p. In this way, the similarity relationship between sentences can be better handled in the dual encoder between queries, affirmative paragraphs and negative paragraphs. While the idea is appealing, it's not easy to implement due to two main problems. First, the sequence information output in the BERT model is positively correlated with non-semantic similarity, which means that the tensor distance of the output of SBERT and DPR is often messy. Second, manually labeling data is costly. And there is no open source dataset like this at present, so we made our own multi-threshold extraction information based on the Stanford University question and answer dataset. Aims for targeted training on the features of the model.</p>
<p>SECTION III.Methodology
A. Overview
In this section, we describe IDS-Extract, which performs semantic search to compress the dataset passed to the model for training. Through multi-batch deletion, input constraints of different memory models and training requirements across different downstream tasks can be met. Firstly we train BERT models with different sizes, including Tiny, Mini, Small, Base and subsequent T5 models. Then by using the IDS-extraction method directly, they can smoothly retain the original semantic environment in the stream and shorten the length to meet the length requirements of the model. The method can be divided into three steps: 1) IDS-extraction; 2) Multiple sequence length training; 3) Model evaluation. Due to the huge cost of training a large superset on a heavy fine-tuning task and choosing a compressed model under specific constraints, we introduce a technique that can reduce the time and improve the efficiency of fine-tuning.</p>
<p><img src="https://raw.githubusercontent.com/Gzk738/vps_picgo/master/images/20230423221412.png" alt="20230423221412">
The confirmation of the answer index can be confirmed by the full text or part of the sentence. The first sentence can determine the position of the answer. Other information (Half content, Content) can be omitted. Where S(q, p)represents the similarity of paragraphs under SBERT, D(q, p)represents the similarity of paragraphs in the DPR, D1, D2 to Dn representations to make BERT datasets for various downstream tasks, our input representations are able to unambiguously represent a sentence and a pair of sentences (e.g, Question, Content) in a sequence of tokens. In the whole work, the training data is continuously refined during the process of different extraction thresholds. The D1 data set is the result of the IDS extraction of the threshold s1, so it has long sequence data. Therefore, for the Base model that can process long data, all texts can be considered. With the improvement of the extraction degree, the length of the sequence data is further reduced until Dn. Therefore, the tiny model is used for learning, even if the tiny can process the sequence data. It is very short, but since the text has been extracted, the small model can still process it without ignoring some parts under the premise of guaranteeing the text information.</p>
<p>B. Calculatie
The SBERT network uses a triplet network structure model to calculate the semantic similarity of two sentences. Among them, this method can reduce the huge computational overhead, so in this task, we use SBERT to calculate the semantic correlation between questions and texts: as we all know, generally speaking, the semantic similarity between a question Q and a text P should be small, Because the question needs to dig out the position of the answer from the text, but if it is compared with other blocks that do not even have an answer, in the contribution score of the first semantic similarity, the block of the text containing the answer often has a higher similarity.
<img src="https://raw.githubusercontent.com/Gzk738/vps_picgo/master/images/20230423221448.png" alt="20230423221448">
Dense encoder will map this paragraph to a D-dimensional real vector. We can use him to form an index of M text segments to facilitate retrieval. Another Encoder E(x) maps the question into a D-dimensional vector, and then retrieves k text segments whose vectors are the closest to the question vector. The vector dot product used by the approximation function, as:
<img src="https://raw.githubusercontent.com/Gzk738/vps_picgo/master/images/20230423221504.png" alt="20230423221504">
We consider the straight line path Rn from the baseline x′ to the input x and compute the gradients at all points along the path. Integrated gradients are obtained by cumulating these gradients. Specifically, integrated gradients are defined as the path integral of the gradients along the straight line path from the baseline x′ to the input x. the gradients along the path γ(α) for α ∈ [0, 1]
<img src="https://raw.githubusercontent.com/Gzk738/vps_picgo/master/images/20230423221518.png" alt="20230423221518">
For many deep networks, it is possible to choose a baseline with predictions close to 0, x′ →0 In this way, the baseline can be ignored when interpreting the attribution results and only the attribution results are assigned to the input without considering the baseline. Path Methods: The integrated gradient method accumulates the gradient along the line between the baseline input and our IDS retriever uses the Dense Paragraph Retriever (DPR) and SBERT fusion together to perform semantic similarity detection on text blocks, which maps any text paragraph to a d-dimensional real-valued vector, and provides all M paragraphs that we will use for retrieval Build an index. At runtime, IDS applies different encoders to map the input text to d-dimensional vectors and retrieves the k paragraphs of which vectors are closest to the question vector. We define the similarity between question and text as:
<img src="https://raw.githubusercontent.com/Gzk738/vps_picgo/master/images/20230423221535.png" alt="20230423221535">
According to different extraction degrees, We use these datasets to measure the size of SBERT respectively. And the large, medium and small models of T5 are trained and evaluated.</p>
<h2 id="section-ivexperimental"><a href="#section-ivexperimental" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>SECTION IV.Experimental</h2>
<p>A. Multi-model performance
The main task studied in this paper is to test models of different sizes on the same task with different levels of difficulty, so we conduct experiments on the Stanford University question answering dataset: SQuAD Stanford question answering dataset is a reading comprehension dataset, which is developed by crowdsourced staff Consists of questions posed in a set of Wikipedia articles, where the answer to each question is a piece of text or span that may not be answered by the corresponding reading article or question. In our experiments, we reused the NQ version authored by DPR. We use DPR, SBERT and Integration Gradient to perform decimation operations on the question answering dataset, where the score for each option. Query, and IG(q,p) represents the contribution of each token in the gradient integration algorithm The average of the sums is shown in Figure 3.</p>
<p>Before using the gradient integral to process the model, the prime minister performs an independent interpretation experiment with the model: In order to show that the interpretation result is independent of the model, I use the bert-large-uncased-whole-word-masking-finetuned-squad model, Perform independent and cascaded independent experiments on it.
<img src="https://raw.githubusercontent.com/Gzk738/vps_picgo/master/images/20230423221614.png" alt="20230423221614">
<img src="https://raw.githubusercontent.com/Gzk738/vps_picgo/master/images/20230423221629.png" alt="20230423221629">
B. Data verification
Formally, we introduce the extraction relationship between paragraphs, and create a new extraction data set in the order of relevance. The sequence data with high scores are the candidate paragraphs for relabeling, in order to prove that the difficulty index of our books is from hard to hard. Simple and incremental, we directly apply it to the training model for evaluation, and the results are shown in Figure 2. We can see from the figure that as the threshold increases from 0 to 100%, the performance of the model is also improving. Since the degree of text extraction increases with the threshold, the ratio of ground truth , and also increased to 42.85 with the improvement of the extraction level, all the examples included the answer.</p>
<h2 id="section-viconclusion"><a href="#section-viconclusion" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>SECTION VI.Conclusion</h2>
<p>This paper proposes a new model training method, which can reduce the amount of data required and improve the performance of the model on the original basis. Since the size determines the performance of the model. I consider using difficulty reduction to improve model performance. I extract significant parts of the text, reduce text complexity, and reduce text length. Improved performance for small models that cannot handle long sequences of data. And has a higher effect on small size models. The method exploits the retrieval ability of dense passage retrieval, the semantic understanding ability of SBERT, and the Integral Gradient method based on attribution method to capture more comprehensive semantic relations. Thereby, abstracting and summarizing text semantics from different degrees can be realized. Implementing our approach, I make important technical contributions to compress training data procedures and propose a dataset that can be manually adjusted in size and complexity. Therefore, it can be used to fine-tune models of different sizes for better performance. Extensive results demonstrate the effectiveness of our method. This is the first time the model has been trained on compressed data. Has been considered for question answering systems. I believe that such an idea itself is worth exploring when designing new training mechanisms. In future work, we will design more data compression techniques and apply current retrieval methods to downstream tasks such as question answering.</p>
<h2 id="acknowledgment"><a href="#acknowledgment" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>ACKNOWLEDGMENT</h2>
<p>This work was partly supported by the National Research Foundation of Korea(NRF) grant funded by the Korea government(MSIT) (No. NRF-2021R1A2C3011169)[50%] and the National Research Foundation of Korea(NRF) grant funded by the Korea government (MSIT) (No. 2022R1A5A7026673)[50%]</p>

            </div>

            
    
    
        <ul class="post-copyright">
            <li class="copyright-item author"><span class="copyright-item-text">作者</span>：<a href="guozikun.xyz" class="p-author h-card" target="_blank" rel="noopener">铅笔与橡皮</a></li>
            
                
                
                
                
                <li class="copyright-item link"><span class="copyright-item-text">链接</span>：<a href="/tech/ids/" target="_blank" rel="noopener">https://guozikun.xyz/tech/ids/</a></li>
            
            <li class="copyright-item license"><span class="copyright-item-text">许可</span>：copyright hugo</li>
            
        </ul>
    



        </article>

        <ins class="adsbygoogle" style="display:block; text-align:center;"
    data-ad-client=""
    data-ad-slot=""></ins>
<script>
    (adsbygoogle = window.adsbygoogle || []).push({});
</script>


        


        


        <div class="post-share">

        
            <div class="share-text">分享：</div>
        

        <div class="share-items">

            
                <div class="share-item twitter">
                    
                    <a href="https://twitter.com/share?url=https://guozikun.xyz/tech/ids/&amp;text=IDS-Extract:Downsizing%20Deep%20Learning%20Model%20For%20Question%20and%20Answering&amp;hashtags=&amp;via=gzk" title="分享到「Twitter」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon twitter-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </div>
            

            
                <div class="share-item facebook">
                    
                    <a href="https://www.facebook.com/sharer/sharer.php?u=https://guozikun.xyz/tech/ids/&amp;hashtag=%23" title="分享到「Facebook」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon facebook-icon"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg></a>
                </div>
            

            
                <div class="share-item linkedin">
                    
                    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://guozikun.xyz/tech/ids/&amp;title=IDS-Extract:Downsizing%20Deep%20Learning%20Model%20For%20Question%20and%20Answering&amp;summary=Published%20in:%202023%20International%20Conference%20on%20Electronics,%20Information,%20and%20Communication%20%28ICEIC%29%0aAbstract:%20In%20recent%20years,%20Question-answering%20systems%20are%20extensively%20used%20in%20human-computer%20systems,%20and%20the%20accuracy%20rate%20on%20a%20large%20scale%20is%20increasing.%20However,%20in%20actual%20deployment,%20a%20large%20number%20of%20parameters%20are%20often%20accompanied%20by%20a%20large%20amount%20of%20memory%20and%20long-term%20processing%20requirements.&amp;source=%e9%93%85%e7%ac%94%e4%b8%8e%e6%a9%a1%e7%9a%ae" title="分享到「LinkedIn」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon linkedin-icon"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
                </div>
            

            
                <div class="share-item telegram">
                    
                    <a href="https://t.me/share/url?url=https://guozikun.xyz/tech/ids/&amp;text=IDS-Extract:Downsizing%20Deep%20Learning%20Model%20For%20Question%20and%20Answering" title="分享到「Telegram」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon telegram-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </div>
            

            
                <div class="share-item weibo">
                    
                    <a href="https://service.weibo.com/share/share.php?&amp;url=https://guozikun.xyz/tech/ids/&amp;title=IDS-Extract:Downsizing%20Deep%20Learning%20Model%20For%20Question%20and%20Answering&amp;pic=https://guozikun.xyz/icons/apple-touch-icon.png&amp;searchPic=false" title="分享到「新浪微博」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon weibo-icon"><path d="M407 177.6c7.6-24-13.4-46.8-37.4-41.7-22 4.8-28.8-28.1-7.1-32.8 50.1-10.9 92.3 37.1 76.5 84.8-6.8 21.2-38.8 10.8-32-10.3zM214.8 446.7C108.5 446.7 0 395.3 0 310.4c0-44.3 28-95.4 76.3-143.7C176 67 279.5 65.8 249.9 161c-4 13.1 12.3 5.7 12.3 6 79.5-33.6 140.5-16.8 114 51.4-3.7 9.4 1.1 10.9 8.3 13.1 135.7 42.3 34.8 215.2-169.7 215.2zm143.7-146.3c-5.4-55.7-78.5-94-163.4-85.7-84.8 8.6-148.8 60.3-143.4 116s78.5 94 163.4 85.7c84.8-8.6 148.8-60.3 143.4-116zM347.9 35.1c-25.9 5.6-16.8 43.7 8.3 38.3 72.3-15.2 134.8 52.8 111.7 124-7.4 24.2 29.1 37 37.4 12 31.9-99.8-55.1-195.9-157.4-174.3zm-78.5 311c-17.1 38.8-66.8 60-109.1 46.3-40.8-13.1-58-53.4-40.3-89.7 17.7-35.4 63.1-55.4 103.4-45.1 42 10.8 63.1 50.2 46 88.5zm-86.3-30c-12.9-5.4-30 .3-38 12.9-8.3 12.9-4.3 28 8.6 34 13.1 6 30.8.3 39.1-12.9 8-13.1 3.7-28.3-9.7-34zm32.6-13.4c-5.1-1.7-11.4.6-14.3 5.4-2.9 5.1-1.4 10.6 3.7 12.9 5.1 2 11.7-.3 14.6-5.4 2.8-5.2 1.1-10.9-4-12.9z"/></svg></a>
                </div>
            

            
                <div class="share-item douban">
                    
                    <a href="https://www.douban.com/share/service?href=https://guozikun.xyz/tech/ids/&amp;name=IDS-Extract:Downsizing%20Deep%20Learning%20Model%20For%20Question%20and%20Answering&amp;text=Published%20in:%202023%20International%20Conference%20on%20Electronics,%20Information,%20and%20Communication%20%28ICEIC%29%0aAbstract:%20In%20recent%20years,%20Question-answering%20systems%20are%20extensively%20used%20in%20human-computer%20systems,%20and%20the%20accuracy%20rate%20on%20a%20large%20scale%20is%20increasing.%20However,%20in%20actual%20deployment,%20a%20large%20number%20of%20parameters%20are%20often%20accompanied%20by%20a%20large%20amount%20of%20memory%20and%20long-term%20processing%20requirements." title="分享到「豆瓣」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon douban-icon"><path d="M.643.92v2.412h22.714V.92H.643zm1.974 4.926v9.42h18.764v-9.42H2.617zm2.72 2.408H18.69v4.605H5.338V8.254zm1.657 7.412l-2.512.938c1.037 1.461 1.87 2.825 2.512 4.091H0v2.385h24v-2.385h-6.678c.818-1.176 1.589-2.543 2.303-4.091l-2.73-.938a29.952 29.952 0 01-2.479 5.03h-4.75c-.786-1.962-1.677-3.641-2.672-5.03Z"/></svg></a>
                </div>
            

            
                <div class="share-item qq">
                    
                    <a href="https://connect.qq.com/widget/shareqq/index.html?url=https://guozikun.xyz/tech/ids/&amp;title=IDS-Extract:Downsizing%20Deep%20Learning%20Model%20For%20Question%20and%20Answering&amp;summary=Published%20in:%202023%20International%20Conference%20on%20Electronics,%20Information,%20and%20Communication%20%28ICEIC%29%0aAbstract:%20In%20recent%20years,%20Question-answering%20systems%20are%20extensively%20used%20in%20human-computer%20systems,%20and%20the%20accuracy%20rate%20on%20a%20large%20scale%20is%20increasing.%20However,%20in%20actual%20deployment,%20a%20large%20number%20of%20parameters%20are%20often%20accompanied%20by%20a%20large%20amount%20of%20memory%20and%20long-term%20processing%20requirements.&amp;pics=https://guozikun.xyz/icons/apple-touch-icon.png&amp;site=%e9%93%85%e7%ac%94%e4%b8%8e%e6%a9%a1%e7%9a%ae" title="分享到「QQ」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qq-icon"><path d="M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704z"/></svg></a>
                </div>
            

            
                <div class="share-item qzone">
                    
                    <a href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://guozikun.xyz/tech/ids/&amp;title=IDS-Extract:Downsizing%20Deep%20Learning%20Model%20For%20Question%20and%20Answering&amp;summary=Published%20in:%202023%20International%20Conference%20on%20Electronics,%20Information,%20and%20Communication%20%28ICEIC%29%0aAbstract:%20In%20recent%20years,%20Question-answering%20systems%20are%20extensively%20used%20in%20human-computer%20systems,%20and%20the%20accuracy%20rate%20on%20a%20large%20scale%20is%20increasing.%20However,%20in%20actual%20deployment,%20a%20large%20number%20of%20parameters%20are%20often%20accompanied%20by%20a%20large%20amount%20of%20memory%20and%20long-term%20processing%20requirements.&amp;pics=https://guozikun.xyz/icons/apple-touch-icon.png&amp;site=%e9%93%85%e7%ac%94%e4%b8%8e%e6%a9%a1%e7%9a%ae" title="分享到「QQ 空间」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon qzone-icon"><path d="M23.985 9.202c-.032-.099-.127-.223-.334-.258-.207-.036-7.351-1.406-7.351-1.406s-.105-.022-.198-.07c-.092-.047-.127-.167-.127-.167S12.447.956 12.349.77C12.25.583 12.104.532 12 .532c-.104 0-.251.051-.349.238-.098.186-3.626 6.531-3.626 6.531s-.035.12-.128.167c-.092.047-.197.07-.197.07S.556 8.908.348 8.943c-.208.036-.302.16-.333.258a.477.477 0 0 0 .125.449l5.362 5.49s.072.08.119.172c.016.104.005.21.005.21s-1.189 7.242-1.22 7.45.075.369.159.43c.083.062.233.106.421.013.189-.093 6.812-3.261 6.812-3.261s.098-.044.201-.061c.103-.017.201.061.201.061s6.623 3.168 6.812 3.261c.188.094.338.049.421-.013a.463.463 0 0 0 .159-.43c-.021-.14-.93-5.677-.93-5.677.876-.54 1.425-1.039 1.849-1.747-2.594.969-6.006 1.717-9.415 1.866-.915.041-2.41.097-3.473-.015-.678-.071-1.17-.144-1.243-.438-.053-.215.054-.46.545-.831a2640.5 2640.5 0 0 1 2.861-2.155c1.285-.968 3.559-2.47 3.559-2.731 0-.285-2.144-.781-4.037-.781-1.945 0-2.275.132-2.811.168-.488.034-.769.005-.804-.138-.06-.248.183-.389.588-.568.709-.314 1.86-.594 1.984-.626.194-.052 3.082-.805 5.618-.535 1.318.14 3.244.668 3.244 1.276 0 .342-1.721 1.494-3.225 2.597-1.149.843-2.217 1.561-2.217 1.688 0 .342 3.533 1.241 6.689 1.01l.003-.022c.048-.092.119-.172.119-.172l5.362-5.49a.477.477 0 0 0 .127-.449z"/></svg></a>
                </div>
            

            
                <div class="share-item qrcode">
                    <div class="qrcode-container" title="通过「二维码」"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qrcode-icon"><path d="M0 224h192V32H0v192zM64 96h64v64H64V96zm192-64v192h192V32H256zm128 128h-64V96h64v64zM0 480h192V288H0v192zm64-128h64v64H64v-64zm352-64h32v128h-96v-32h-32v96h-64V288h96v32h64v-32zm0 160h32v32h-32v-32zm-64 0h32v32h-32v-32z"/></svg><div id="qrcode-img"></div>
                    </div>
                    <script src="https://cdn.jsdelivr.net/npm/qrcode-generator@1.4.4/qrcode.min.js"></script>

<script>
    var typeNumber = 0;
    var errorCorrectionLevel = 'L';
    var qr = qrcode(typeNumber, errorCorrectionLevel);
    qr.addData('https:\/\/guozikun.xyz\/tech\/ids\/');
    qr.make();
    document.getElementById('qrcode-img').innerHTML = qr.createImgTag();
</script>

                </div>
            

        </div>

    </div>




        
    
    



        
    



        


        


        


        


    </div>
</main>


            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>


            
    <footer id="footer" class="footer">
        <div class="footer-inner">
            <div class="site-info">©&nbsp;1996–2023&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg>&nbsp;铅笔与橡皮</div><div class="site-copyright">copyright hugo</div>

            
    
        <ul class="socials"><li class="socials-item">
                    <a href="/rss.xml" target="_blank" rel="external noopener" title="RSS"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M19.199 24C19.199 13.467 10.533 4.8 0 4.8V0c13.165 0 24 10.835 24 24h-4.801zM3.291 17.415c1.814 0 3.293 1.479 3.293 3.295 0 1.813-1.485 3.29-3.301 3.29C1.47 24 0 22.526 0 20.71s1.475-3.294 3.291-3.295zM15.909 24h-4.665c0-6.169-5.075-11.245-11.244-11.245V8.09c8.727 0 15.909 7.184 15.909 15.91z"/></svg></a>
                </li><li class="socials-item">
                    <a href="mailto:reuixiy@gmail.com" target="_blank" rel="external noopener" title="Email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://github.com/reuixiy" target="_blank" rel="external noopener" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://twitter.com/reuixiy" target="_blank" rel="external noopener" title="Twitter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://t.me/yixiuer" target="_blank" rel="external noopener" title="Telegram"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon social-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </li></ul>
    



            
        </div>
    </footer>


        </div>
        

        








    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@latest/dist/medium-zoom.min.js"></script>

<script>
    let imgNodes = document.querySelectorAll('div.post-body img');
    imgNodes = Array.from(imgNodes).filter(node => node.parentNode.tagName !== "A");

    mediumZoom(imgNodes, {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>




    <script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module" defer></script>




    
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    




    </body>
</html>
